{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Modules"
      ],
      "metadata": {
        "id": "6YqZd3YT8EKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ufMRWg9Ys-L_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import os\n",
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hardware Accelerator Check"
      ],
      "metadata": {
        "id": "LvrCwMES74W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjUFclRx78qk",
        "outputId": "5abbd97b-e63c-4a56-f541-0b352d2471af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Pg-WAkTVzo2Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "ACZiV7w89N0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining data transforms for train and test datasets\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Xv5JdFPh-iSs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing CIFAR10 train and test datasets\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpYR5mrD9R99",
        "outputId": "f8183453-42b0-4694-f0c9-be25b1a26baa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12886708.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of data points in train dataset\n",
        "\n",
        "trainset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwMYna8fAYG9",
        "outputId": "8520f613-716a-462c-c87d-d977005a6494"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomCrop(size=(32, 32), padding=4)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of data points in test dataset\n",
        "\n",
        "testset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoCxJBHyBCNH",
        "outputId": "95c07616-af06-4afb-9e62-780fb152905b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating data loaders for train and test datasets\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "fk708NCiBX7T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The different classes in CIFAR10 dataset are\n",
        "\n",
        "trainset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h29ZWJm5DAuh",
        "outputId": "4eefd6ff-3251-42a5-c55d-f9d3bd178cc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18 NN Basic Block"
      ],
      "metadata": {
        "id": "EInXPW4McCbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "F2qgIJrKdlBR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18 Architecture"
      ],
      "metadata": {
        "id": "Q426VQXygcsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "P0v523cAghUa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the Model"
      ],
      "metadata": {
        "id": "OLeaBXhHjhwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet18(BasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "J7pxIGqijjz2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "    print(\"Device is set to CUDA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvhKWuXTjzEZ",
        "outputId": "65d0a6ed-b8bb-475e-fb9e-0a74bf4e2d88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is set to CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0 # start from epoch 0 or last checkpoint epoch"
      ],
      "metadata": {
        "id": "dtC0jvf_kQYU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Optimizer"
      ],
      "metadata": {
        "id": "AcyhvqZfkuTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "metadata": {
        "id": "tY8PnX79kx6f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "LjZwX5IGlC6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))"
      ],
      "metadata": {
        "id": "8mH6UrxulEb7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "PlaAGeTrlGZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n"
      ],
      "metadata": {
        "id": "yfc1pPlclHu1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate"
      ],
      "metadata": {
        "id": "OwmJ6hWSpuy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, 80):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTKUBhizpzv7",
        "outputId": "25d8a8b5-9dfd-48e3-c693-dd99d8f00053"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Train Loss: 0.913 | Train Acc: 67.826% (33913/50000)\n",
            "Test Loss: 1.009 | Test Acc: 65.350% (6535/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "Train Loss: 0.762 | Train Acc: 73.386% (36693/50000)\n",
            "Test Loss: 0.729 | Test Acc: 74.700% (7470/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            "Train Loss: 0.659 | Train Acc: 77.294% (38647/50000)\n",
            "Test Loss: 0.744 | Test Acc: 74.720% (7472/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            "Train Loss: 0.606 | Train Acc: 79.118% (39559/50000)\n",
            "Test Loss: 0.969 | Test Acc: 68.960% (6896/10000)\n",
            "\n",
            "Epoch: 4\n",
            "Train Loss: 0.563 | Train Acc: 80.596% (40298/50000)\n",
            "Test Loss: 0.608 | Test Acc: 78.730% (7873/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            "Train Loss: 0.535 | Train Acc: 81.614% (40807/50000)\n",
            "Test Loss: 0.621 | Test Acc: 78.800% (7880/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            "Train Loss: 0.510 | Train Acc: 82.400% (41200/50000)\n",
            "Test Loss: 0.689 | Test Acc: 77.660% (7766/10000)\n",
            "\n",
            "Epoch: 7\n",
            "Train Loss: 0.486 | Train Acc: 83.454% (41727/50000)\n",
            "Test Loss: 0.616 | Test Acc: 78.790% (7879/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Train Loss: 0.469 | Train Acc: 83.870% (41935/50000)\n",
            "Test Loss: 0.749 | Test Acc: 75.280% (7528/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Train Loss: 0.457 | Train Acc: 84.308% (42154/50000)\n",
            "Test Loss: 0.592 | Test Acc: 80.230% (8023/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            "Train Loss: 0.438 | Train Acc: 85.006% (42503/50000)\n",
            "Test Loss: 0.694 | Test Acc: 77.660% (7766/10000)\n",
            "\n",
            "Epoch: 11\n",
            "Train Loss: 0.432 | Train Acc: 85.226% (42613/50000)\n",
            "Test Loss: 0.546 | Test Acc: 81.710% (8171/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            "Train Loss: 0.418 | Train Acc: 85.692% (42846/50000)\n",
            "Test Loss: 0.680 | Test Acc: 78.060% (7806/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Train Loss: 0.414 | Train Acc: 85.834% (42917/50000)\n",
            "Test Loss: 0.538 | Test Acc: 81.310% (8131/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Train Loss: 0.403 | Train Acc: 86.108% (43054/50000)\n",
            "Test Loss: 0.628 | Test Acc: 78.830% (7883/10000)\n",
            "\n",
            "Epoch: 15\n",
            "Train Loss: 0.396 | Train Acc: 86.416% (43208/50000)\n",
            "Test Loss: 0.481 | Test Acc: 83.320% (8332/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            "Train Loss: 0.392 | Train Acc: 86.672% (43336/50000)\n",
            "Test Loss: 0.498 | Test Acc: 83.230% (8323/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Train Loss: 0.387 | Train Acc: 86.720% (43360/50000)\n",
            "Test Loss: 0.476 | Test Acc: 84.020% (8402/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            "Train Loss: 0.372 | Train Acc: 87.200% (43600/50000)\n",
            "Test Loss: 0.680 | Test Acc: 78.290% (7829/10000)\n",
            "\n",
            "Epoch: 19\n",
            "Train Loss: 0.372 | Train Acc: 87.234% (43617/50000)\n",
            "Test Loss: 0.535 | Test Acc: 82.130% (8213/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Train Loss: 0.370 | Train Acc: 87.380% (43690/50000)\n",
            "Test Loss: 0.531 | Test Acc: 82.060% (8206/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Train Loss: 0.367 | Train Acc: 87.450% (43725/50000)\n",
            "Test Loss: 0.494 | Test Acc: 83.150% (8315/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Train Loss: 0.366 | Train Acc: 87.572% (43786/50000)\n",
            "Test Loss: 0.607 | Test Acc: 79.880% (7988/10000)\n",
            "\n",
            "Epoch: 23\n",
            "Train Loss: 0.351 | Train Acc: 87.922% (43961/50000)\n",
            "Test Loss: 0.725 | Test Acc: 76.870% (7687/10000)\n",
            "\n",
            "Epoch: 24\n",
            "Train Loss: 0.359 | Train Acc: 87.732% (43866/50000)\n",
            "Test Loss: 0.656 | Test Acc: 79.530% (7953/10000)\n",
            "\n",
            "Epoch: 25\n",
            "Train Loss: 0.352 | Train Acc: 87.990% (43995/50000)\n",
            "Test Loss: 0.507 | Test Acc: 82.930% (8293/10000)\n",
            "\n",
            "Epoch: 26\n",
            "Train Loss: 0.351 | Train Acc: 88.092% (44046/50000)\n",
            "Test Loss: 0.529 | Test Acc: 83.120% (8312/10000)\n",
            "\n",
            "Epoch: 27\n",
            "Train Loss: 0.343 | Train Acc: 88.396% (44198/50000)\n",
            "Test Loss: 0.483 | Test Acc: 84.000% (8400/10000)\n",
            "\n",
            "Epoch: 28\n",
            "Train Loss: 0.344 | Train Acc: 88.318% (44159/50000)\n",
            "Test Loss: 0.510 | Test Acc: 83.600% (8360/10000)\n",
            "\n",
            "Epoch: 29\n",
            "Train Loss: 0.341 | Train Acc: 88.362% (44181/50000)\n",
            "Test Loss: 0.454 | Test Acc: 84.640% (8464/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            "Train Loss: 0.335 | Train Acc: 88.552% (44276/50000)\n",
            "Test Loss: 0.487 | Test Acc: 83.430% (8343/10000)\n",
            "\n",
            "Epoch: 31\n",
            "Train Loss: 0.337 | Train Acc: 88.394% (44197/50000)\n",
            "Test Loss: 0.628 | Test Acc: 80.640% (8064/10000)\n",
            "\n",
            "Epoch: 32\n",
            "Train Loss: 0.331 | Train Acc: 88.808% (44404/50000)\n",
            "Test Loss: 0.632 | Test Acc: 79.720% (7972/10000)\n",
            "\n",
            "Epoch: 33\n",
            "Train Loss: 0.336 | Train Acc: 88.564% (44282/50000)\n",
            "Test Loss: 0.451 | Test Acc: 85.060% (8506/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 34\n",
            "Train Loss: 0.331 | Train Acc: 88.766% (44383/50000)\n",
            "Test Loss: 0.455 | Test Acc: 84.420% (8442/10000)\n",
            "\n",
            "Epoch: 35\n",
            "Train Loss: 0.330 | Train Acc: 88.628% (44314/50000)\n",
            "Test Loss: 0.529 | Test Acc: 82.460% (8246/10000)\n",
            "\n",
            "Epoch: 36\n",
            "Train Loss: 0.329 | Train Acc: 88.812% (44406/50000)\n",
            "Test Loss: 0.409 | Test Acc: 86.300% (8630/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 37\n",
            "Train Loss: 0.319 | Train Acc: 89.226% (44613/50000)\n",
            "Test Loss: 0.501 | Test Acc: 83.450% (8345/10000)\n",
            "\n",
            "Epoch: 38\n",
            "Train Loss: 0.326 | Train Acc: 88.894% (44447/50000)\n",
            "Test Loss: 0.645 | Test Acc: 79.550% (7955/10000)\n",
            "\n",
            "Epoch: 39\n",
            "Train Loss: 0.316 | Train Acc: 89.120% (44560/50000)\n",
            "Test Loss: 0.452 | Test Acc: 84.770% (8477/10000)\n",
            "\n",
            "Epoch: 40\n",
            "Train Loss: 0.319 | Train Acc: 89.094% (44547/50000)\n",
            "Test Loss: 0.502 | Test Acc: 84.690% (8469/10000)\n",
            "\n",
            "Epoch: 41\n",
            "Train Loss: 0.312 | Train Acc: 89.240% (44620/50000)\n",
            "Test Loss: 0.522 | Test Acc: 83.610% (8361/10000)\n",
            "\n",
            "Epoch: 42\n",
            "Train Loss: 0.318 | Train Acc: 89.238% (44619/50000)\n",
            "Test Loss: 0.425 | Test Acc: 86.320% (8632/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 43\n",
            "Train Loss: 0.314 | Train Acc: 89.302% (44651/50000)\n",
            "Test Loss: 0.480 | Test Acc: 83.770% (8377/10000)\n",
            "\n",
            "Epoch: 44\n",
            "Train Loss: 0.301 | Train Acc: 89.752% (44876/50000)\n",
            "Test Loss: 0.505 | Test Acc: 83.760% (8376/10000)\n",
            "\n",
            "Epoch: 45\n",
            "Train Loss: 0.309 | Train Acc: 89.590% (44795/50000)\n",
            "Test Loss: 0.502 | Test Acc: 83.330% (8333/10000)\n",
            "\n",
            "Epoch: 46\n",
            "Train Loss: 0.296 | Train Acc: 89.984% (44992/50000)\n",
            "Test Loss: 0.442 | Test Acc: 85.070% (8507/10000)\n",
            "\n",
            "Epoch: 47\n",
            "Train Loss: 0.301 | Train Acc: 89.840% (44920/50000)\n",
            "Test Loss: 0.434 | Test Acc: 85.730% (8573/10000)\n",
            "\n",
            "Epoch: 48\n",
            "Train Loss: 0.306 | Train Acc: 89.548% (44774/50000)\n",
            "Test Loss: 0.362 | Test Acc: 87.940% (8794/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            "Train Loss: 0.295 | Train Acc: 89.886% (44943/50000)\n",
            "Test Loss: 0.442 | Test Acc: 84.940% (8494/10000)\n",
            "\n",
            "Epoch: 50\n",
            "Train Loss: 0.289 | Train Acc: 90.114% (45057/50000)\n",
            "Test Loss: 0.437 | Test Acc: 85.850% (8585/10000)\n",
            "\n",
            "Epoch: 51\n",
            "Train Loss: 0.292 | Train Acc: 89.986% (44993/50000)\n",
            "Test Loss: 0.407 | Test Acc: 86.510% (8651/10000)\n",
            "\n",
            "Epoch: 52\n",
            "Train Loss: 0.291 | Train Acc: 89.996% (44998/50000)\n",
            "Test Loss: 0.581 | Test Acc: 81.730% (8173/10000)\n",
            "\n",
            "Epoch: 53\n",
            "Train Loss: 0.294 | Train Acc: 89.884% (44942/50000)\n",
            "Test Loss: 0.429 | Test Acc: 86.160% (8616/10000)\n",
            "\n",
            "Epoch: 54\n",
            "Train Loss: 0.284 | Train Acc: 90.256% (45128/50000)\n",
            "Test Loss: 0.429 | Test Acc: 86.100% (8610/10000)\n",
            "\n",
            "Epoch: 55\n",
            "Train Loss: 0.286 | Train Acc: 90.164% (45082/50000)\n",
            "Test Loss: 0.429 | Test Acc: 86.350% (8635/10000)\n",
            "\n",
            "Epoch: 56\n",
            "Train Loss: 0.283 | Train Acc: 90.394% (45197/50000)\n",
            "Test Loss: 0.472 | Test Acc: 84.790% (8479/10000)\n",
            "\n",
            "Epoch: 57\n",
            "Train Loss: 0.283 | Train Acc: 90.400% (45200/50000)\n",
            "Test Loss: 0.425 | Test Acc: 86.320% (8632/10000)\n",
            "\n",
            "Epoch: 58\n",
            "Train Loss: 0.281 | Train Acc: 90.506% (45253/50000)\n",
            "Test Loss: 0.436 | Test Acc: 86.170% (8617/10000)\n",
            "\n",
            "Epoch: 59\n",
            "Train Loss: 0.280 | Train Acc: 90.404% (45202/50000)\n",
            "Test Loss: 0.387 | Test Acc: 87.040% (8704/10000)\n",
            "\n",
            "Epoch: 60\n",
            "Train Loss: 0.268 | Train Acc: 90.812% (45406/50000)\n",
            "Test Loss: 0.483 | Test Acc: 84.700% (8470/10000)\n",
            "\n",
            "Epoch: 61\n",
            "Train Loss: 0.270 | Train Acc: 90.712% (45356/50000)\n",
            "Test Loss: 0.359 | Test Acc: 87.930% (8793/10000)\n",
            "\n",
            "Epoch: 62\n",
            "Train Loss: 0.272 | Train Acc: 90.728% (45364/50000)\n",
            "Test Loss: 0.723 | Test Acc: 79.640% (7964/10000)\n",
            "\n",
            "Epoch: 63\n",
            "Train Loss: 0.272 | Train Acc: 90.696% (45348/50000)\n",
            "Test Loss: 0.476 | Test Acc: 85.080% (8508/10000)\n",
            "\n",
            "Epoch: 64\n",
            "Train Loss: 0.266 | Train Acc: 90.892% (45446/50000)\n",
            "Test Loss: 0.382 | Test Acc: 87.430% (8743/10000)\n",
            "\n",
            "Epoch: 65\n",
            "Train Loss: 0.269 | Train Acc: 90.760% (45380/50000)\n",
            "Test Loss: 0.384 | Test Acc: 87.040% (8704/10000)\n",
            "\n",
            "Epoch: 66\n",
            "Train Loss: 0.265 | Train Acc: 91.014% (45507/50000)\n",
            "Test Loss: 0.407 | Test Acc: 86.900% (8690/10000)\n",
            "\n",
            "Epoch: 67\n",
            "Train Loss: 0.261 | Train Acc: 91.124% (45562/50000)\n",
            "Test Loss: 0.528 | Test Acc: 83.560% (8356/10000)\n",
            "\n",
            "Epoch: 68\n",
            "Train Loss: 0.254 | Train Acc: 91.336% (45668/50000)\n",
            "Test Loss: 0.412 | Test Acc: 86.090% (8609/10000)\n",
            "\n",
            "Epoch: 69\n",
            "Train Loss: 0.261 | Train Acc: 91.104% (45552/50000)\n",
            "Test Loss: 0.365 | Test Acc: 88.060% (8806/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 70\n",
            "Train Loss: 0.252 | Train Acc: 91.310% (45655/50000)\n",
            "Test Loss: 0.380 | Test Acc: 87.230% (8723/10000)\n",
            "\n",
            "Epoch: 71\n",
            "Train Loss: 0.252 | Train Acc: 91.434% (45717/50000)\n",
            "Test Loss: 0.415 | Test Acc: 86.480% (8648/10000)\n",
            "\n",
            "Epoch: 72\n",
            "Train Loss: 0.252 | Train Acc: 91.296% (45648/50000)\n",
            "Test Loss: 0.359 | Test Acc: 87.980% (8798/10000)\n",
            "\n",
            "Epoch: 73\n",
            "Train Loss: 0.252 | Train Acc: 91.336% (45668/50000)\n",
            "Test Loss: 0.448 | Test Acc: 85.550% (8555/10000)\n",
            "\n",
            "Epoch: 74\n",
            "Train Loss: 0.243 | Train Acc: 91.704% (45852/50000)\n",
            "Test Loss: 0.416 | Test Acc: 86.570% (8657/10000)\n",
            "\n",
            "Epoch: 75\n",
            "Train Loss: 0.239 | Train Acc: 91.748% (45874/50000)\n",
            "Test Loss: 0.441 | Test Acc: 85.970% (8597/10000)\n",
            "\n",
            "Epoch: 76\n",
            "Train Loss: 0.241 | Train Acc: 91.794% (45897/50000)\n",
            "Test Loss: 0.469 | Test Acc: 85.170% (8517/10000)\n",
            "\n",
            "Epoch: 77\n",
            "Train Loss: 0.242 | Train Acc: 91.652% (45826/50000)\n",
            "Test Loss: 0.444 | Test Acc: 85.700% (8570/10000)\n",
            "\n",
            "Epoch: 78\n",
            "Train Loss: 0.234 | Train Acc: 92.062% (46031/50000)\n",
            "Test Loss: 0.484 | Test Acc: 84.780% (8478/10000)\n",
            "\n",
            "Epoch: 79\n",
            "Train Loss: 0.232 | Train Acc: 92.036% (46018/50000)\n",
            "Test Loss: 0.425 | Test Acc: 86.250% (8625/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6eFWRVKJzvP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}